<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Exploratory Analysis of Road Bike Trip Data • asds2024.nils.practical</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Exploratory Analysis of Road Bike Trip Data">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">asds2024.nils.practical</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.2.0.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../articles/get-started.html">Get started</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/data.html">Data</a></li>
    <li><a class="dropdown-item" href="../articles/analyses.html">Analyses</a></li>
    <li><hr class="dropdown-divider"></li>
    <li><a class="dropdown-item" href="../articles/presentation.html">Mid-Term Presentation</a></li>
    <li><a class="dropdown-item" href="../articles/article.html">Final Report</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">



<script src="article_files/kePrint-0.0.1/kePrint.js"></script><link href="article_files/lightable-0.0.1/lightable.css" rel="stylesheet">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Exploratory Analysis of Road Bike Trip Data</h1>
            <h3 data-toc-skip class="subtitle">CAS Advanced Statistical
Data Science 2024</h3>
                        <h4 data-toc-skip class="author">Nils S.</h4>
            
            <h4 data-toc-skip class="date">10.09.2025</h4>
      

      <div class="d-none name"><code>article.Rmd</code></div>
    </div>

    
        <div class="abstract">
      <p class="abstract">Abstract</p>
      <p>For the final project of the CAS program Advanced Statistical
      Data Science, a real world data set of our own choosing was to be
      analyzed, using methods learned in class.</p>
      <p>This report represents an exploratory analysis of road bike
      data collected during the bike seasons from 2018 to 2023, using
      different statistical means to try to find
      statistically-significant patterns or anomalies in the data.</p>
    </div>
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>The final module of the CAS ASDS is a practical project. The topic of
the project can be freely chosen by the students, e.g. using data from
their work environment or from elsewhere.</p>
<p>The data I chose for my final project is data collected from road
bike trips during the years 2018 to 2023. Data was collected using a
GPS-enabled bike computer, with complementary sensors for heart rate,
cadence, and speed data. In total, the preprocessed data comprises
approximately 160000 data points, collected during 157 trips. The actual
number of trips during those seasons was higher, however, due to a data
corruption in the bike computer’s memory, an unknown number of trip
recordings was lost. Figure shows the number of tracks for each year in
the data set, suggesting that a data block (or data blocks) containing
records for 2022 and 2023 was lost.</p>
<div class="figure">
<img src="article_files/figure-html/fig-tracks-per-year-1.png" alt="\label{fig-tracks-per-year}Available trip data by year and month" width="45%"><img src="article_files/figure-html/fig-tracks-per-year-2.png" alt="\label{fig-tracks-per-year}Available trip data by year and month" width="45%"><p class="caption">
Available trip data by year and month
</p>
</div>
<p>Figure shows the geographic component of the available data on a map,
with the tracks in red. Routes driven more frequently appear more
saturated, rarely-driven routes appear lighter (e.g. the route to lake
Thun only appears once in the data set).</p>
<div class="figure">
<img src="article_files/figure-html/fig-tracks-map-1.png" alt="\label{fig-tracks-map}Geographic track data (in red) on a map of cantons Berne and Fribourg" width="336"><p class="caption">
Geographic track data (in red) on a map of cantons Berne and Fribourg
</p>
</div>
<p>Since the data was not collected for the purpose of this project,
i.e. it is not data from a controlled experiment, it is not as
well-formed as would be desirable for an ideal analysis. Instead, the
project is an exploratory analysis of available data.</p>
</div>
<div class="section level2">
<h2 id="analyses">Analyses<a class="anchor" aria-label="anchor" href="#analyses"></a>
</h2>
<p>The data is a time series, however, due to uneven temporal spacing of
the data points, missing values, etc., the methods learned in class
could not be used in this case. For this reason other methods were
attempted, mainly linear models of different sorts, as introduced in the
lectures on mixed-effects models (“Lineare gemischte Modelle”, <span class="citation">Vock (2023)</span>), and analysis of high-dimensional
data (“Analyse hochdimensionaler Daten”, <span class="citation">Städler
(2024)</span>), and some methods introduced in the lecture on
unsupervised learning (“Unüberwachtes Lernen und Dimensionsreduktion”,
<span class="citation">Dümbgen (2024)</span>). These approaches are
problematic (due to the data being correlated to some degree, and
because the fundamental nature of the data is a time series, which
should be analyzed using methods designed for such data), but to get a
first impression the analyses performed should still be okay, and their
results should still be valid.</p>
<p>The code and some additional description for the analyses can be
found in <code><a href="../articles/analyses.html">vignette("analyses")</a></code> for the package accompanying
this document. This report will mainly present the results of the
analyses, along with remarks and conclusions.</p>
<div class="section level3">
<h3 id="global-linear-models">Global Linear Models<a class="anchor" aria-label="anchor" href="#global-linear-models"></a>
</h3>
<p>The first approach is to fit global linear models, i.e. models using
all the data. The focus was finding effects influencing the average
speed for a track. Questions I tried to answer were:</p>
<ul>
<li>is there an effect of temperature?</li>
<li>what are the effects of track length, average inclination, and heart
rate?</li>
<li>does a previous track (i.e. the previous training) have a
significant impact / what aspect of a previous track has an impact
(previous track length/inclination/heart rate, time since previous
training, …)?</li>
<li>is there a training effect over the course of the season, i.e. does
the average speed increase over the course of the year?</li>
</ul>
<div class="section level4">
<h4 id="temperature-effects">Temperature Effects<a class="anchor" aria-label="anchor" href="#temperature-effects"></a>
</h4>
<p>The first model using only the average temperature as a predictor for
the average speed did not show any significant effect. The original idea
behind fitting the model was based on the subjective feeling that warmer
temperatures lead to lower speed. The temperature coefficient in the
fitted model does indicate such a tendency, however, it’s p-value is so
large that this might be pure chance. Additionally, the coefficient is
so small that even if it was significant, temperature fluctuations
within reasonable limits would barely influence the average speed. If
such a tiny effect is actually present, much more data would be needed
to detect it with any degree of statistical significance, however.</p>
<p>Another aspect to consider is that the assumed “lower temperatures
mean higher speed” relationship is too simplistic: there is probably an
optimal temperature, below which the average speed decreases again. Such
a relationship cannot be modeled by simply fitting a straight line to
the data.</p>
<p>An attempt was made to fit splines to the temperature data, but that
did not result in viable models, either. Slightly better-fitting models
could probably have been achieved using splines, however, due to time
constraints these ideas were not pursued further. Instead, I focused on
trying to find other patterns in the data, since the results obtained
when trying to fit a model for the temperature did not seem too
promising.</p>
</div>
<div class="section level4">
<h4 id="effects-of-distance-inclination-and-heart-rate">Effects of Distance, Inclination, and Heart Rate<a class="anchor" aria-label="anchor" href="#effects-of-distance-inclination-and-heart-rate"></a>
</h4>
<p>The second model fitted is based on a track’s total distance, average
inclination, and average heart rate. Intuitively, this should be a
relatively promising model to explain the average speed. The model can
then serve as a baseline reference to compare other models to.</p>
<p>This model explains about 58% of the total variance in the data, and
shows that average inclination and average heart rate are highly
significant predictors. Somewhat contrary to the initial expectation,
though, a track’s total distance has no significant effect, at least not
for the usual 5% confidence threshold: the distance effect has a p-Value
of just above 5%.</p>
<p>The model seems to fit the data relatively well, with some outliers
visible in the diagnostic plots. The more obvious outliers are caused by
tracks that were rarely driven (e.g. the route of track 2, driven on
July 31st, 2018, was only driven once), highlighting their difference
from tracks that were driven frequently.</p>
</div>
<div class="section level4">
<h4 id="effects-of-previous-training-sessions">Effects of Previous Training Sessions<a class="anchor" aria-label="anchor" href="#effects-of-previous-training-sessions"></a>
</h4>
<p>Since one training session can influence a subsequent training
session (e.g. because there was not enough time for recovery between
sessions, or because after recovering from the first session, the
overall fitness was better), an attempt was made to model such an
effect. The most important predictors are probably still the track’s
distance, inclination, and heart rate, but the previous track’s details
(i.e. the previous track’s distance, inclination, and heart rate) were
also considered. Additionally, the time between the training sessions
was included in the model, so that e.g. for two tracks
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>t</mi><mn>1</mn></msub><annotation encoding="application/x-tex">t_1</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>t</mi><mn>2</mn></msub><annotation encoding="application/x-tex">t_2</annotation></semantics></math>
driven 2 days apart, the effect
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>t</mi><mn>1</mn></msub><annotation encoding="application/x-tex">t_1</annotation></semantics></math>
has on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>t</mi><mn>2</mn></msub><annotation encoding="application/x-tex">t_2</annotation></semantics></math>
can be different from the same two tracks being driven 20 days
apart.</p>
<p>The fitted model explains about 3% of additional variance in the data
when compared to the previous, simpler model. However, only the time
since the previous track, and the previous track’s distance are
significant. Considering that track distance strongly correlates with
the duration of the track, it could seem logical to use the training
time of the previous track as a predictor instead of the previous
track’s distance, however, that approach produces a model with slightly
lower
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>R</mi><mn>2</mn></msup><annotation encoding="application/x-tex">R^2</annotation></semantics></math>,
and the previous track’s duration is actually a less significant
predictor than the distance.</p>
<p>Overall, though, the extended model is not very useful. It is more
complex and less explainable (for example, the average speed decreases
with increasing time since the last training, but increases with the
previous training’s distance; thus, a track driven the day after driving
a very long track should have a higher average speed than a track driven
a few days after a shorter track, which does not match past
experiences). Additionally, the diagnostics look a bit worse than for
the simpler model (the QQ-plot of the residuals looks a bit worse, and
the residuals-vs-leverage plot shows some observations with higher
leverage than before). All of these drawbacks only result in a model
that explains an additional 3% of variance.</p>
</div>
<div class="section level4">
<h4 id="effects-of-the-training-season">Effects of the Training Season<a class="anchor" aria-label="anchor" href="#effects-of-the-training-season"></a>
</h4>
<p>Another approach to take previous trainings into account is to check
for effects of the training season: within a given year, have tracks
later in the year a higher average speed than tracks earlier in the
year? Assuming that the fitness level is lowest directly after the
winter, it should rise over the course of the season, i.e. the more
training sessions were performed, the higher the fitness level should
be. Multiple models were evaluated for this approach, some using the
month, and a final one using the calendar week.</p>
<p>Starting with the simplest model of using just the month as a
predictor, there is no significant effect. Considering that an increase
in fitness probably goes along with driving (on average) longer tracks,
which are more exhausting, and therefore reducing average speed,
additional predictors are needed to detect the effect of the training
progress during the season. Thus, the same predictors used for the basic
model were added back, together with their interactions with the month.
Thus, for example, depending on training progress during the season
(i.e. month), the average heart rate could have a different effect per
month. This model already has 32 coefficients, compared to just four
coefficients for the basic model. However, three of the coefficients are
actually <code>NA</code> values (the interaction effects for October),
and of the remaining coefficients, only four (apart from the intercept)
are significant (at a 5% confidence level). One of the significant
effects is the average inclination (which was already significant in the
basic model), the other three significant effects are some of the
interaction effects. There is no obvious pattern for which effects are
significant (other than the inclination), which makes this model harder
to explain than the basic one, while offering the advantage of
explaining about 71% of the variance. The diagnostics look a bit worse
for the more complex model, though, with the QQ-plot of the residuals
slightly worse than for the basic model, and the
residuals-vs-leverage-plot noticeably worse.</p>
<p>Attempting to fit a model for the season with higher temporal
resolution (using calendar week instead of month) is pointless, though:
there is data for 29 different calendar weeks, resulting in 28
coefficients for the calendar weeks alone, plus an additional 28
coefficients for each interaction, and some more coefficients for the
other effects, for a total of 116 coefficients. Of those, 15 result in
<code>NA</code>s, however, and of the remaining non-<code>NA</code>
coefficients, only one is significant. Even the intercept and the
inclination are not significant in this model, and the diagnostic plots
look clearly worse than those of the basic or month-based models.</p>
<p>The difficulty in finding effects for the training season are
probably at least in part caused by lack of data: there are only six
seasons for which there is data, and at least for three of those seasons
the data is incomplete: for the first year (2018), there is no data for
the start of the season (because the bike computer was only bought
mid-season), and for 2022 and 2023 there is missing data due to memory
corruption in the bike computer, with (at least) the later part of the
2022 season and the beginning of the 2023 season missing. Even if these
seasons were completely available, it would still be only six seasons
worth of data from which to extrapolate. With the missing data, the
choice is between removing the incomplete seasons (and trying to
extrapolate from even less data of just the remaining three seasons), or
using all data and potentially skewing the results. The latter option
was chosen, the former might be something to try in the future. Out of
all the training season-based models fitted so far, only the one using
the month and its interactions seems usable, however, due to the model’s
complexity the basic model still seems like a more robust and useful
choice (despite explaining quite a bit less variance).</p>
</div>
<div class="section level4">
<h4 id="lasso-regression-using-elasticnet">Lasso Regression using ElasticNet<a class="anchor" aria-label="anchor" href="#lasso-regression-using-elasticnet"></a>
</h4>
<p>After fitting the preceding models, which used manually-selected
predictors, I tried Lasso regression <span class="citation">(Tay,
Narasimhan, and Hastie 2023)</span> to see which predictors would be
selected. Since there are some more predictors available than those that
were used until now, the idea was that if there were important
predictors that were not considered, those would now be found by the
Lasso regression.</p>
<p>In a first round of Lasso regression, using 12 available predictors
to model the average speed, only one predictor (one of the heart rate
zones) was eliminated by the Lasso.</p>
<p>This model is still relatively large, and many of the predictors are
highly correlated: the heart rate-based predictors are correlated with
each other, and a track’s time and distance are also highly correlated.
By eliminating correlated predictors (only keeping average heart rate as
a heart rate-based predictor, and keeping distance but not time), we
reduce the number of available predictors to 5. Trying Lasso regression
on the reduced set of predictors results in a model based on distance,
inclination, and heart rate. This is exactly the same set of predictors
that was already used for the basic model, i.e. the initial selection
seems to have been appropriate. This also means, however, that Lasso
regression does not really help improve the models created before, it
only confirms the gut feeling based on which the basic model was
constructed.</p>
</div>
<div class="section level4">
<h4 id="random-effects">Random Effects<a class="anchor" aria-label="anchor" href="#random-effects"></a>
</h4>
<p>A last thing to try for the global linear model is to add random
effects <span class="citation">(Pinheiro, Bates, and R Core Team
2023)</span>. For example, we could assume that a model based on
distance, inclination, and heart rate (i.e. the basic model) is a good
fit for the data, but that there are slight differences in average speed
among the years, e.g. caused by different decreases in fitness during
the winter. This could be modelled by a random effect for the year.
Another possibility would be a random effect to model differences among
different routes that are not explained by differences in route length
or inclination. Furthermore, effects could be nested, e.g. there could
be a route-specific random effect that varies among years, or there
could be additional random effects for the month within each year. The
nested effects could explain e.g. a situation where certain routes seem
easier in some years, or fluctuations in fitness during the year
(i.e. per month).</p>
<p>Fitting such models shows that a model with a random effect for the
route is not better than the basic model, however, a model with a random
effect for the year is quite certainly better than the basic model. Both
nested models (i.e. route in year, and month in year) are also slightly
better than the model with just a random effect for the year.</p>
<p>Out of the three mixed models that perform better than the basic
model, the simple model with just a random effect for the year is
probably the most appealing one: it is the simplest of the three, and a
random variation between years seems intuitively plausible. The nested
models are only slightly better performance-wise, but harder to
understand. Furthermore, the nested random effects appear less
intuitive. Considering for example that routes are fixed, a random
effect for the route seems less likely than a deterministic, fixed
effect for the route. The random effect might just work to compensate
for some route parameters that are not available in the data. Similarly,
instead of the random effect for the month, some sort of fixed effect
would seem more plausible (fitness or training effect of some sort), but
again, the random effect might compensate for some relationship that
would need additional data to model as a fixed effect.</p>
</div>
</div>
<div class="section level3">
<h3 id="principal-component-analysis">Principal Component Analysis<a class="anchor" aria-label="anchor" href="#principal-component-analysis"></a>
</h3>
<p>After trying to fit linear models to the data with mixed success, I
tried to determine the main sources of variance in the data. For this, a
principal component analysis was done for 15 variables.</p>
<p>The two most important principal components explain almost 60% of the
total variance, with the first component’s main influencing factors
being the time, distance, inclination, and altitude gain, and the second
component’s main influences being the heart rate-related variables.
Considering which predictors were found to be statistically relevant in
the linear models, this does not seem surprising.</p>
<p>What was surprising, though, was the biplot of the first two
principal components, which showed two clearly separated groups of
observations.</p>
</div>
<div class="section level3">
<h3 id="clustering">Clustering<a class="anchor" aria-label="anchor" href="#clustering"></a>
</h3>
<p>After seeing the distinct groups of observations in the PCA biplots,
the next thing I tried was clustering of the data points.</p>
<p>The first approach was a Gaussian mixture model <span class="citation">(Scrucca et al. 2023)</span>, which can be fitted
without any additional parameters, i.e. given the data it will
automatically determine a clustering without any further inputs. The
resulting clustering is based on four groups. When looking at the groups
in a speed-vs-distance plot, the grouping seems to be based mostly on
distance (which, for the given data, is a good indicator for the
route).</p>
<p>A second clustering approach that was tried is DBSCAN <span class="citation">(Hahsler and Piekenbrock 2023)</span>. For this
algorithm, a preparatory k-nearest-neighbor distance computation has to
be performed, and a value of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ε</mi><annotation encoding="application/x-tex">\varepsilon</annotation></semantics></math>
has to be eyeballed from the resulting plot. Different values for
<code>k</code> and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ε</mi><annotation encoding="application/x-tex">\varepsilon</annotation></semantics></math>
were tried, however, most of the time the result was a clustering with
only two or three groups (i.e. one or two actual classes, plus one
“noise” class). For
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">k = 1</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ε</mi><mo>=</mo><mn>2.1</mn></mrow><annotation encoding="application/x-tex">\varepsilon = 2.1</annotation></semantics></math>,
three classes and a “noise” class were found. Again, the classes are
very clearly based on track distance (even more obviously so than for
the Gaussian mixture model).</p>
<p>Considering that the clustering algorithms seem to cluster mostly by
track distance, a classification based on a track’s route seems natural.
This is the most obvious way of classifying the tracks, especially when
considering that some tracks were driven quite often. The route-based
classification was therefore added manually, to develop models that can
use a track’s route as an additional predictor. Additionally, the route
classification was also used for random effects to fit additional
mixed-effects models (see section ).</p>
</div>
<div class="section level3">
<h3 id="route-specific-linear-models">Route-specific Linear Models<a class="anchor" aria-label="anchor" href="#route-specific-linear-models"></a>
</h3>
<p>With the manually-assigned classes, some of the approaches tried for
the global linear models can be retried on a per-class basis. However,
since all tracks in a class are trips along the same route,
route-specific information like distance or inclination are not useful
predictors for these models. Furthermore, there are now substantially
fewer tracks which can be used to fit a model. The most
frequently-driven route has 55 tracks, with the second- and third-most
driven routes having 52, and 10 tracks, respectively. For this reason,
only the three most-frequently-driven routes were selected to try to fit
a basic model for. A slightly more complex model was only tried for the
most frequent route.</p>
<p>The first attempt for a simple linear model used the average heart
rate, and temperature to model average track speed, since the other
predictors used in the basic global model were not applicable when
looking at tracks for the same route. Again, as for the global model,
for none of the three routes a significant effect of the temperature can
be found. Thus, the only predictor which has a significant effect is the
average heart rate, with an increase in average speed of between ca. 0.5
and 1 km/h for every 10 bpm increase in average heart rate. The
diagnostics plots don’t look too bad for the routes with &gt; 50 tracks
(apart from the residual QQ-plots, which show quite obvious deviations
from the diagonal, for one route at the lower end, for the other at the
higher end of values). For the route with only 10 observations, however,
there is too little data, which becomes obvious in the diagnostics
plots. So even though the model for that track shows a significant
effect of the average heart rate, the model itself is not useful for
making predictions.</p>
<p>Attempting to find a training effect over the course of the season
for the most frequent route again finds no significant effect, however,
this might at least in part be due to lack of data, considering there is
only one month for which there are at least ten observations.</p>
</div>
<div class="section level3">
<h3 id="dynamic-time-warping">Dynamic Time-Warping<a class="anchor" aria-label="anchor" href="#dynamic-time-warping"></a>
</h3>
<p>While not by itself a statistical analysis method, dynamic
time-warping <span class="citation">(Giorgino 2009)</span> can be used
to map data points of one track to the data points of another track,
making it possible to compare them even when they do not have the exact
same number of data points. This could be used to find parts of a route
that vary a lot (or very little) among different tracks for that route,
and then analyze those deviations. Ideas are to compare all tracks along
the same route to a reference track (e.g. the fastest or slowest track),
or to compare subsequent tracks to each other. Obvious analysis ideas
are, again, looking for influences of temperature or training progress
for certain route sections with high variability among tracks,
e.g. “does temperature influence performance on particularly steep parts
of a route”.</p>
<p>This is still ongoing, however, since the necessary analyses could
not be finished in time for the final submission deadline.</p>
</div>
</div>
<div class="section level2">
<h2 id="conclusion">Conclusion<a class="anchor" aria-label="anchor" href="#conclusion"></a>
</h2>
<p>While quite a few statistical methods learned during the CAS were
applied, the overall outcome of the analysis is not particularly
impressive. Conclusions that can be drawn with relative certainty:</p>
<ul>
<li>a track’s average inclination, and the average heart rate almost
certainly have an influence on the average speed, a track’s distance is
less important</li>
<li>for a given route, tracks with a higher average heart rate tend to
have a higher average speed</li>
<li>temperature seems to have a negligible effect</li>
<li>from the available data, no improvement in overall fitness over the
course of the season can be concluded</li>
</ul>
<p>The fact that temperature does not seem to have an effect, and that
there is no apparent training effect seems surprising (as in: does not
correspond to subjective observations), as does the fact that distance
seems to have a lower-than-expected influence. However, the strong
influence of inclination and average heart rate seems obvious.</p>
<p>What is also clear, however, is that most models do not fit very
well, even though more fine-tuning could probably improve most of the
models to some degree. This is at least in part because of the (assumed)
structure of the data (i.e. most effects probably have some sort of
curved shape, with an optimal point from which results taper off in both
directions). Another aspect for the suboptimal fit is likely due the
fact that the available data is lacking in (at least) two aspects:</p>
<ul>
<li>There are simply not enough observations to reliably detect small
effects, especially in more complex models; reasons are the data loss
for the 2022/2023 seasons, and the fact that data was only collected for
six seasons in total</li>
<li>There are other factors that influence performance, like wind, other
exercise sessions, resting periods (sleep etc.), and many more. These
factors were not measured, though, so their effects invisibly influence
the data in unpredictable ways.</li>
</ul>
<p>While the lack of data cannot be compensated for, there are still
other possibilities to explore. Things to attempt in the future
(i.e. after the final submission deadline) are improvements to the
linear models (exploring the effect of certain interactions, e.g.
distance and inclination, or splines and other curve-shaped fits),
continuing to experiment with dynamic time-warping, and taking a look at
more advanced time-series models than those that were introduced in the
CAS lecture on that topic <span class="citation">(Hayoz and Hüsler
2023)</span>.</p>
</div>
<div class="section level2">
<h2 class="unnumbered" id="appendix-a---data">Appendix A - Data<a class="anchor" aria-label="anchor" href="#appendix-a---data"></a>
</h2>
<p>The raw data used for this project was recorded by a GPS-enabled bike
computer, paired with a chest strap-style heart rate sensor, and a
combined speed and cadence sensor. Data was recorded at five second
intervals. The individual tracks (i.e. trip recordings) were exported as
CSV files.</p>
<p>The (slightly censored) raw data is available in the sources of the R
package accompanying this document. More details about the data can be
found in the package’s <code><a href="../articles/data.html">vignette("data")</a></code>, or by looking at
the documentation for the data directly, i.e. <code><a href="../reference/tracks.html">?tracks</a></code>,
<code><a href="../reference/track_details.html">?track_details</a></code>, or <code><a href="../reference/track_classes.html">?track_classes</a></code>.</p>
</div>
<div class="section level2">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-lduembgen2024" class="csl-entry">
Dümbgen, Lutz. 2024. <span>“Vorlesungsskript
<span>U</span>n<span>ü</span>berwachtes <span>L</span>ernen Und
<span>D</span>imensionsreduktion.”</span> Institut für mathematische
Statistik und Versicherungslehre, Universit<span>ä</span>t Bern.
</div>
<div id="ref-R-dtw" class="csl-entry">
Giorgino, Toni. 2009. <span>“Computing and Visualizing Dynamic Time
Warping Alignments in <span>R</span>: The <span class="nocase">dtw</span> Package.”</span> <em>Journal of Statistical
Software</em> 31 (7): 1–24. <a href="https://doi.org/10.18637/jss.v031.i07" class="external-link">https://doi.org/10.18637/jss.v031.i07</a>.
</div>
<div id="ref-R-dbscan" class="csl-entry">
Hahsler, Michael, and Matthew Piekenbrock. 2023. <em>Dbscan:
Density-Based Spatial Clustering of Applications with Noise (DBSCAN) and
Related Algorithms</em>. <a href="https://CRAN.R-project.org/package=dbscan" class="external-link">https://CRAN.R-project.org/package=dbscan</a>.
</div>
<div id="ref-shayoz2023" class="csl-entry">
Hayoz, Stefanie, and Jürg Hüsler. 2023. <span>“Vorlesungsskript
<span>Z</span>eitreihenanalyse.”</span> Institut für mathematische
Statistik und Versicherungslehre, Universit<span>ä</span>t Bern.
</div>
<div id="ref-R-nlme" class="csl-entry">
Pinheiro, José, Douglas Bates, and R Core Team. 2023. <em>Nlme: Linear
and Nonlinear Mixed Effects Models</em>. <a href="https://CRAN.R-project.org/package=nlme" class="external-link">https://CRAN.R-project.org/package=nlme</a>.
</div>
<div id="ref-R-mclust" class="csl-entry">
Scrucca, Luca, Chris Fraley, T. Brendan Murphy, and Adrian E. Raftery.
2023. <em>Model-Based Clustering, Classification, and Density Estimation
Using <span class="nocase">mclust</span> in <span>R</span></em>.
Chapman; Hall/CRC. <a href="https://doi.org/10.1201/9781003277965" class="external-link">https://doi.org/10.1201/9781003277965</a>.
</div>
<div id="ref-nstaedler2024" class="csl-entry">
Städler, Nicolas. 2024. <span>“Analysis of High-Dimensional Data -
Prediction and Feature Assessment.”</span> 2024. <a href="https://bookdown.org/staedler_n/highdimstats/" class="external-link">https://bookdown.org/staedler_n/highdimstats/</a>.
</div>
<div id="ref-R-glmnet" class="csl-entry">
Tay, J. Kenneth, Balasubramanian Narasimhan, and Trevor Hastie. 2023.
<span>“Elastic Net Regularization Paths for All Generalized Linear
Models.”</span> <em>Journal of Statistical Software</em> 106 (1): 1–31.
<a href="https://doi.org/10.18637/jss.v106.i01" class="external-link">https://doi.org/10.18637/jss.v106.i01</a>.
</div>
<div id="ref-mvock2023" class="csl-entry">
Vock, Michael. 2023. <span>“Vorlesungsskript <span>L</span>ineare
Gemischte <span>M</span>odelle.”</span> Institut für mathematische
Statistik und Versicherungslehre, Universit<span>ä</span>t Bern.
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Nils S..</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer>
</div>





  </body>
</html>
